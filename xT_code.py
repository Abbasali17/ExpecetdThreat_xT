# -*- coding: utf-8 -*-
"""Untitled73.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FOlFQvDVQA9S_qziaUo4sp6X1VAyFiVG
"""

!pip install pandas numpy statsbombpy plotly scipy tqdm mplsoccer

# --- LIBRARIES ---
import pandas as pd
import numpy as np
from statsbombpy import sb
from tqdm.notebook import tqdm # Use tqdm for non-notebook environments
import matplotlib.pyplot as plt
from mplsoccer import Pitch, VerticalPitch
import os # <<< --- ADD THIS IMPORT ---

# ======================================================================
# --- CONFIGURATION ---
# ======================================================================
PITCH_LENGTH = 120
PITCH_WIDTH = 80
GRID_X = 16
GRID_Y = 12
TOTAL_ZONES = GRID_X * GRID_Y

COMPS_TO_LOAD = {
    (43, 3): "Men's World Cup 2018",
    (55, 43): "Men's Euro 2020",
}

MAX_ITERATIONS = 100
CONVERGENCE_TOLERANCE = 1e-6
MINIMUM_MINUTES_THRESHOLD = 270
HIGH_XT_ACTION_THRESHOLD = 0.03

# --- Define directory to save plots ---
PLOT_SAVE_DIR = "output_plots"
# Create the directory if it doesn't exist
os.makedirs(PLOT_SAVE_DIR, exist_ok=True) # exist_ok=True prevents error if dir already exists

# ======================================================================
# --- HELPER FUNCTIONS ---
# ======================================================================
# (Functions remain the same)
def get_zone_index(x, y, grid_x=GRID_X, grid_y=GRID_Y, length=PITCH_LENGTH, width=PITCH_WIDTH):
    if pd.isna(x) or pd.isna(y) or x < 0 or x > length or y < 0 or y > width: return -1
    x = np.clip(x, 0, length); y = np.clip(y, 0, width)
    ix = min(int((x / length) * grid_x), grid_x - 1)
    iy = min(int((y / width) * grid_y), grid_y - 1)
    return iy * grid_x + ix

def get_zone_center(index, grid_x=GRID_X, grid_y=GRID_Y, length=PITCH_LENGTH, width=PITCH_WIDTH):
    if index < 0 or index >= grid_x * grid_y: return None, None
    iy = index // grid_x; ix = index % grid_x
    center_x = (ix + 0.5) * (length / grid_x); center_y = (iy + 0.5) * (width / grid_y)
    return center_x, center_y

# ======================================================================
# --- DATA LOADING (MATCHES, LINEUPS, EVENTS) ---
# ======================================================================
# (Data Loading section remains the same as the last working version)
print("--- Starting Data Loading ---")
print("Loading matches...")
all_matches_df = pd.DataFrame()
for (comp_id, season_id), comp_name in COMPS_TO_LOAD.items():
     try:
         matches_raw = sb.matches(competition_id=comp_id, season_id=season_id)
         if matches_raw.empty: continue
         matches = matches_raw.copy()
         matches['home_team_name'] = matches['home_team'].apply(lambda x: x.get('home_team_name', 'Unknown') if isinstance(x, dict) else x if pd.notna(x) else 'Unknown')
         matches['away_team_name'] = matches['away_team'].apply(lambda x: x.get('away_team_name', 'Unknown') if isinstance(x, dict) else x if pd.notna(x) else 'Unknown')
         matches['home_team_id'] = matches['home_team'].apply(lambda x: x.get('home_team_id') if isinstance(x, dict) else None)
         matches['away_team_id'] = matches['away_team'].apply(lambda x: x.get('away_team_id') if isinstance(x, dict) else None)
         matches['competition_name'] = comp_name
         all_matches_df = pd.concat([all_matches_df, matches], ignore_index=True)
         print(f"Loaded and processed {len(matches)} matches for {comp_name}")
     except Exception as e:
         print(f"Could not load or process matches for Comp {comp_id} Season {season_id}: {type(e).__name__} - {e}")
# ... (rest of data loading, minutes calc, feature engineering, xT model build) ...
# --- The bulk of the script is unchanged until the VISUALIZATIONS section ---

if all_matches_df.empty: raise ValueError("No matches loaded successfully.")
print(f"\nFound {len(all_matches_df)} total matches across selected competitions.")
match_ids_to_load = all_matches_df['match_id'].unique()
missing_home_ids = all_matches_df['home_team_id'].isna().sum(); missing_away_ids = all_matches_df['away_team_id'].isna().sum()
if missing_home_ids > 0 or missing_away_ids > 0: print(f"Warning: Found {missing_home_ids} matches missing home_team_id and {missing_away_ids} matches missing away_team_id.")

print("\nLoading lineups...")
all_lineups = {};
for match_id in tqdm(match_ids_to_load, desc="Loading Lineups"):
    try:
        match_info = all_matches_df[all_matches_df['match_id'] == match_id]
        if not match_info.empty: all_lineups[match_id] = sb.lineups(match_id=match_id)
        else: all_lineups[match_id] = None
    except Exception as e: all_lineups[match_id] = None

print("\nLoading events...")
all_events_df = pd.DataFrame(); event_load_success_count = 0
for match_id in tqdm(match_ids_to_load, desc="Loading Events"):
    try:
        match_info = all_matches_df[all_matches_df['match_id'] == match_id]
        if match_info.empty: continue
        events = sb.events(match_id=match_id)
        if events.empty: continue
        cols_to_keep = ['id', 'match_id', 'index', 'period', 'timestamp', 'minute', 'second','type', 'possession', 'possession_team', 'play_pattern', 'team', 'player','location', 'pass_end_location', 'carry_end_location','shot_outcome', 'shot_statsbomb_xg', 'pass_outcome', 'under_pressure','substitution_replacement', 'team_id', 'player_id', 'possession_team_id']
        events = events[[col for col in cols_to_keep if col in events.columns]].copy()
        home_team_id = match_info['home_team_id'].iloc[0]; away_team_id = match_info['away_team_id'].iloc[0]
        if pd.isna(home_team_id) or pd.isna(away_team_id): events['score_difference'] = 0
        elif 'period' not in events.columns or 'timestamp' not in events.columns or 'team_id' not in events.columns: events['score_difference'] = 0
        else:
            events = events.sort_values(by=['period', 'timestamp', 'index']).reset_index(drop=True)
            home_score = 0; away_score = 0; score_diff_list = []
            for i, event in events.iterrows():
                acting_team_id = event.get('team_id'); score_diff = 0
                if pd.notna(acting_team_id):
                    if acting_team_id == home_team_id: score_diff = home_score - away_score
                    elif acting_team_id == away_team_id: score_diff = away_score - home_score
                score_diff_list.append(score_diff)
                if event.get('type') == 'Shot' and event.get('shot_outcome') == 'Goal':
                    if event.get('team_id') == home_team_id: home_score += 1
                    elif event.get('team_id') == away_team_id: away_score += 1
            events['score_difference'] = score_diff_list
        all_events_df = pd.concat([all_events_df, events], ignore_index=True)
        event_load_success_count += 1
    except Exception as e: print(f"Could not process events for match_id {match_id}: {type(e).__name__} - {e}")

if event_load_success_count == 0 or all_events_df.empty: raise ValueError("No events were successfully loaded or processed.")
print(f"\nLoaded and processed events for {event_load_success_count} matches.")

print("\nCalculating approximate minutes played...")
player_minutes = {}; player_minutes_df = pd.DataFrame()
for match_id, lineups in tqdm(all_lineups.items(), desc="Processing Minutes"):
    if lineups is None or not lineups: continue
    match_events = all_events_df[all_events_df['match_id'] == match_id].copy()
    if match_events.empty: continue
    max_min = match_events['minute'].max() if 'minute' in match_events.columns else 90
    max_period = match_events['period'].max() if 'period' in match_events.columns else 2
    approx_total_game_minutes = max(90, max_min)
    if max_period == 3: approx_total_game_minutes = max(105, max_min);
    if max_period == 4: approx_total_game_minutes = max(120, max_min);
    if max_period > 4: approx_total_game_minutes = max(120, max_min)
    sub_events = match_events[match_events['type'] == 'Substitution'].sort_values(by=['period', 'timestamp']) if 'type' in match_events.columns and 'timestamp' in match_events.columns else pd.DataFrame()
    for team_name, lineup_list in lineups.items():
        if not isinstance(lineup_list, list): continue
        for player_info in lineup_list:
            if not isinstance(player_info, dict): continue
            player_id = player_info.get('player_id'); player_name = player_info.get('player_name')
            if player_id is None or player_name is None: continue
            start_minute = 0; sub_on_event = None
            if not sub_events.empty and 'substitution_replacement' in sub_events.columns and 'minute' in sub_events.columns:
                player_subs_on = sub_events[sub_events['substitution_replacement'] == player_name]
                if not player_subs_on.empty: sub_on_event = player_subs_on.iloc[0]; start_minute = sub_on_event.get('minute', 0)
            sub_off_event = None
            if not sub_events.empty and 'player' in sub_events.columns and 'minute' in sub_events.columns:
                 player_subs_off = sub_events[sub_events['player'] == player_name]
                 if not player_subs_off.empty: sub_off_event = player_subs_off.iloc[0]
            end_minute = approx_total_game_minutes
            if sub_off_event is not None: end_minute = sub_off_event.get('minute', approx_total_game_minutes)
            minutes_played = 0
            if pd.notna(start_minute) and pd.notna(end_minute) and start_minute <= end_minute:
                 minutes_played = end_minute - start_minute
                 if minutes_played < 0: minutes_played = 0
            current_total = player_minutes.get(player_id, {'name': player_name, 'total_minutes': 0})
            current_total['total_minutes'] += minutes_played
            player_minutes[player_id] = current_total
if player_minutes:
    player_minutes_df = pd.DataFrame.from_dict(player_minutes, orient='index').reset_index().rename(columns={'index':'player_id'})
    if 'total_minutes' in player_minutes_df.columns:
        player_minutes_df = player_minutes_df[player_minutes_df['total_minutes'] > 1].copy()
        if not player_minutes_df.empty: print(f"Calculated estimated minutes for {len(player_minutes_df)} players (with >1 min).")
        else: print("Calculated minutes, but no players met the >1 min threshold.")
    else: print("Warning: 'total_minutes' column not found after creating DataFrame from dictionary."); player_minutes_df = pd.DataFrame()
else: print("Warning: No player minutes could be calculated."); player_minutes_df = pd.DataFrame()

print("\nPreprocessing events for xT calculation...")
all_events_df['x'] = all_events_df['location'].apply(lambda loc: loc[0] if isinstance(loc, list) else np.nan)
all_events_df['y'] = all_events_df['location'].apply(lambda loc: loc[1] if isinstance(loc, list) else np.nan)
all_events_df['end_x'] = np.nan; all_events_df['end_y'] = np.nan
pass_mask = all_events_df['type'] == 'Pass'; carry_mask = all_events_df['type'] == 'Carry'; shot_mask = all_events_df['type'] == 'Shot'
all_events_df.loc[pass_mask, 'end_x'] = all_events_df.loc[pass_mask, 'pass_end_location'].apply(lambda loc: loc[0] if isinstance(loc, list) else np.nan)
all_events_df.loc[pass_mask, 'end_y'] = all_events_df.loc[pass_mask, 'pass_end_location'].apply(lambda loc: loc[1] if isinstance(loc, list) else np.nan)
all_events_df.loc[carry_mask, 'end_x'] = all_events_df.loc[carry_mask, 'carry_end_location'].apply(lambda loc: loc[0] if isinstance(loc, list) else np.nan)
all_events_df.loc[carry_mask, 'end_y'] = all_events_df.loc[carry_mask, 'carry_end_location'].apply(lambda loc: loc[1] if isinstance(loc, list) else np.nan)
all_events_df.loc[shot_mask, 'end_x'] = all_events_df.loc[shot_mask, 'x']; all_events_df.loc[shot_mask, 'end_y'] = all_events_df.loc[shot_mask, 'y']
all_events_df['start_zone'] = all_events_df.apply(lambda row: get_zone_index(row['x'], row['y']), axis=1)
all_events_df['end_zone'] = all_events_df.apply(lambda row: get_zone_index(row['end_x'], row['end_y']), axis=1)
actions_df = all_events_df[(all_events_df['type'].isin(['Pass', 'Carry', 'Shot'])) & (all_events_df['start_zone'] != -1) & (all_events_df['player_id'].notna())].copy()
actions_df['is_successful_move'] = ((actions_df['type'] == 'Pass') & (actions_df['pass_outcome'].isna()) & (actions_df['end_zone'] != -1) | (actions_df['type'] == 'Carry') & (actions_df['end_zone'] != -1))
actions_df['is_shot'] = actions_df['type'] == 'Shot'; actions_df['is_goal'] = actions_df['shot_outcome'] == 'Goal'
actions_df.loc[actions_df['is_shot'], 'goal_prob'] = actions_df.loc[actions_df['is_shot'], 'shot_statsbomb_xg'].fillna(0)
if actions_df.empty: raise ValueError("No valid actions found after filtering for xT calculation.")
print(f"Prepared {len(actions_df)} actions for xT model input.")

print("\nCalculating zone probabilities and transitions...")
zone_stats = pd.DataFrame(index=range(TOTAL_ZONES))
zone_stats['total_actions'] = actions_df.groupby('start_zone').size(); zone_stats['shot_count'] = actions_df[actions_df['is_shot']].groupby('start_zone').size()
zone_stats['prob_shot'] = (zone_stats['shot_count'] / zone_stats['total_actions']).fillna(0); zone_stats['total_xg'] = actions_df[actions_df['is_shot']].groupby('start_zone')['goal_prob'].sum()
zone_stats['prob_goal_given_shot'] = (zone_stats['total_xg'] / zone_stats['shot_count']).fillna(0); zone_stats.loc[zone_stats['shot_count'] > 0, 'prob_goal_given_shot'] = zone_stats['prob_goal_given_shot'].fillna(0)
zone_stats['move_count'] = actions_df[actions_df['is_successful_move']].groupby('start_zone').size(); zone_stats['prob_move'] = (zone_stats['move_count'] / zone_stats['total_actions']).fillna(0)
zone_stats.fillna(0, inplace=True)
successful_moves = actions_df[actions_df['is_successful_move'] & (actions_df['end_zone'] != -1)].copy()
transitions = successful_moves.groupby(['start_zone', 'end_zone']).size().unstack(fill_value=0); total_moves_from_zone = transitions.sum(axis=1)
transition_matrix = transitions.apply(lambda row: row / total_moves_from_zone[row.name] if row.name in total_moves_from_zone and total_moves_from_zone[row.name] > 0 else row * 0, axis=1)
transition_matrix = transition_matrix.reindex(index=range(TOTAL_ZONES), columns=range(TOTAL_ZONES), fill_value=0.0)
transition_matrix_np = transition_matrix.values; prob_shot_np = zone_stats['prob_shot'].values; prob_move_np = zone_stats['prob_move'].values; prob_goal_given_shot_np = zone_stats['prob_goal_given_shot'].values
print("Solving for xT values iteratively...")
xt_values = np.zeros(TOTAL_ZONES)
for i in tqdm(range(MAX_ITERATIONS), desc="xT Iterations"):
    xt_old = xt_values.copy(); expected_value_move = transition_matrix_np @ xt_old
    xt_values = (prob_shot_np * prob_goal_given_shot_np) + (prob_move_np * expected_value_move)
    diff = np.sum(np.abs(xt_values - xt_old))
    if diff < CONVERGENCE_TOLERANCE: print(f"Converged after {i+1} iterations."); break
else: print(f"Stopped after {MAX_ITERATIONS} iterations. Difference: {diff}")
zone_stats['xt_value'] = xt_values
print("Calculating xT for individual actions...")
def get_xt(row, xt_map):
    start_zone = row['start_zone']; end_zone = row['end_zone']
    if row['type'] == 'Shot': return row['goal_prob']
    elif row['is_successful_move']: xt_start = xt_map.get(start_zone, 0); xt_end = xt_map.get(end_zone, 0); return xt_end - xt_start
    else: return 0
xt_map_dict = zone_stats['xt_value'].to_dict()
actions_df['xt_added'] = actions_df.apply(lambda row: get_xt(row, xt_map_dict), axis=1)
print("xT model building complete.")

# ======================================================================
# --- VISUALIZATIONS ---
# ======================================================================
# --- Visualization 1: xT Surface ---
print("\n--- Generating xT Surface Heatmap ---")
xt_grid = xt_values.reshape((GRID_Y, GRID_X))
pitch1 = VerticalPitch(pitch_type='statsbomb', pitch_color='#f4f4f4', line_color='black', half=False)
fig1, ax1 = pitch1.draw(figsize=(8, 11)) # *** fig1 is the figure object ***
cmap1 = 'magma'
xt_grid_transposed = xt_grid.T
plot_extent = [0, PITCH_WIDTH, 0, PITCH_LENGTH]
im1 = ax1.imshow(xt_grid_transposed, cmap=cmap1, alpha=0.9, aspect='auto', extent=plot_extent, origin='lower', vmin=0, vmax=np.max(xt_grid))
cbar1 = fig1.colorbar(im1, ax=ax1, shrink=0.6); cbar1.set_label('Expected Threat (xT)'); ax1.set_title('Expected Threat (xT) Surface', fontsize=16)
plt.tight_layout()
# --- SAVE PLOT 1 ---
fig1_save_path = os.path.join(PLOT_SAVE_DIR, "xt_surface_heatmap.png")
fig1.savefig(fig1_save_path, dpi=300, bbox_inches='tight')
print(f"Saved xT Surface plot to: {fig1_save_path}")
# --- END SAVE ---
plt.show() # Keep showing the plot in output


# --- Visualization 2: High xT Action Start/End Density ---
print("\n--- Visualizing High xT Action Start/End Zones ---")
high_xt_actions = actions_df[(actions_df['is_successful_move']) & (actions_df['xt_added'] > HIGH_XT_ACTION_THRESHOLD) & (actions_df['end_x'].notna()) & (actions_df['end_y'].notna())].copy()
print(f"Found {len(high_xt_actions)} successful moves with xT > {HIGH_XT_ACTION_THRESHOLD}")
if not high_xt_actions.empty:
    pitch = VerticalPitch(pitch_type='statsbomb', pitch_color='#f4f4f4', line_color='black', line_zorder=2)
    fig_zones, axs_zones = plt.subplots(1, 2, figsize=(14, 11)) # *** fig_zones is the figure object ***
    pitch.draw(ax=axs_zones[0]); pitch.draw(ax=axs_zones[1])
    axs_zones[0].set_title(f'Start Zones of High xT Actions (> {HIGH_XT_ACTION_THRESHOLD} xT)', fontsize=14)
    axs_zones[1].set_title(f'End Zones of High xT Actions (> {HIGH_XT_ACTION_THRESHOLD} xT)', fontsize=14)
    fig_zones.suptitle('Density of High Expected Threat Actions', fontsize=18, y=0.98)
    bin_stats_start = pitch.bin_statistic(high_xt_actions['x'], high_xt_actions['y'], statistic='count', bins=(GRID_X, GRID_Y))
    hm_start = pitch.heatmap(bin_stats_start, ax=axs_zones[0], cmap='viridis', edgecolors='#222222', lw=0.5)
    valid_end_actions = high_xt_actions.dropna(subset=['end_x', 'end_y'])
    if not valid_end_actions.empty:
        bin_stats_end = pitch.bin_statistic(valid_end_actions['end_x'], valid_end_actions['end_y'], statistic='count', bins=(GRID_X, GRID_Y))
        hm_end = pitch.heatmap(bin_stats_end, ax=axs_zones[1], cmap='viridis', edgecolors='#222222', lw=0.5)
        fig_zones.subplots_adjust(right=0.88); cbar_ax = fig_zones.add_axes([0.9, 0.25, 0.02, 0.5])
        cbar = fig_zones.colorbar(hm_end, cax=cbar_ax); cbar.set_label(f'Number of Actions (xT > {HIGH_XT_ACTION_THRESHOLD})')
    else: print("No valid end locations found for high xT actions.")
    # --- SAVE PLOT 2 ---
    fig2_save_path = os.path.join(PLOT_SAVE_DIR, "start_end_density_heatmap.png")
    fig_zones.savefig(fig2_save_path, dpi=300, bbox_inches='tight')
    print(f"Saved Start/End Density plot to: {fig2_save_path}")
    # --- END SAVE ---
    plt.show()
else: print(f"No successful moves found with xT > {HIGH_XT_ACTION_THRESHOLD}.")


# ======================================================================
# --- REFINED EDA ---
# ======================================================================
print("\n--- Exploratory Data Analysis (Focusing on Total xT) ---")
if 'player_id' not in actions_df.columns or 'player' not in actions_df.columns: raise ValueError("Essential columns 'player_id' or 'player' missing from actions_df.")
player_xt_grouped = actions_df.groupby('player_id').agg(total_xt_added=('xt_added', 'sum'), player_name=('player', 'first')).reset_index()
player_positions = {}; print("Attempting to extract player positions from lineups...")
for match_id, lineups in all_lineups.items():
     if lineups is None or not lineups: continue
     for team_name, lineup_list in lineups.items():
         if not isinstance(lineup_list, list): continue
         for player_info in lineup_list:
             if not isinstance(player_info, dict): continue
             player_id = player_info.get('player_id'); position = player_info.get('position', {}).get('name', 'Unknown')
             if player_id is not None and player_id not in player_positions: player_positions[player_id] = position
player_positions_df = pd.DataFrame(player_positions.items(), columns=['player_id', 'position'])
player_summary = pd.merge(player_xt_grouped, player_positions_df, on='player_id', how='left')
player_summary['position'] = player_summary['position'].fillna('Unknown')
print(f"\nTop 15 Players by Total xT Added:"); print(player_summary.sort_values(by='total_xt_added', ascending=False).head(15)[['player_name', 'position', 'total_xt_added']])
FORWARD_POSITIONS = ['Forward', 'Center Forward', 'Left Wing', 'Right Wing', 'Striker']; MIDFIELD_POSITIONS = ['Midfielder', 'Center Midfield', 'Attacking Midfield', 'Defensive Midfield', 'Left Midfield', 'Right Midfield']
forwards_summary = player_summary[player_summary['position'].isin(FORWARD_POSITIONS)]; midfielders_summary = player_summary[player_summary['position'].isin(MIDFIELD_POSITIONS)]
if not forwards_summary.empty: print(f"\nTop 10 Forwards by Total xT Added:"); print(forwards_summary.sort_values(by='total_xt_added', ascending=False).head(10)[['player_name', 'position', 'total_xt_added']])
else: print("\nNo players found matching Forward positions for ranking.")
if not midfielders_summary.empty: print(f"\nTop 10 Midfielders by Total xT Added:"); print(midfielders_summary.sort_values(by='total_xt_added', ascending=False).head(10)[['player_name', 'position', 'total_xt_added']])
else: print("\nNo players found matching Midfielder positions for ranking.")

N_TOP_PLAYERS_PLOT = 10
top_player_ids = player_summary.sort_values(by='total_xt_added', ascending=False).head(N_TOP_PLAYERS_PLOT)['player_id'].tolist()
top_players_actions_df = actions_df[actions_df['player_id'].isin(top_player_ids)].copy()
plot_data_pivot = pd.pivot_table(top_players_actions_df,values='xt_added',index=['player_id', 'player'], columns='type', aggfunc='sum',fill_value=0)
if 'Shot' in plot_data_pivot.columns: plot_data_pivot.rename(columns={'Shot': 'Shot xT (xG)'}, inplace=True)
cols_to_plot = ['Pass', 'Carry', 'Shot xT (xG)'];
for col in cols_to_plot:
    if col not in plot_data_pivot.columns: plot_data_pivot[col] = 0
plot_data = plot_data_pivot[cols_to_plot].copy() # Use .copy() to avoid SettingWithCopyWarning
plot_data['Total'] = plot_data.sum(axis=1) # Now this modification is safe
plot_data = plot_data.sort_values(by='Total', ascending=False).drop(columns='Total')

if not plot_data.empty:
    print(f"\nPlotting Action Type Breakdown for Top {N_TOP_PLAYERS_PLOT} Players by Total xT:")
    plot_data_for_plot = plot_data.reset_index(); plot_data_for_plot['player_label'] = plot_data_for_plot['player']
    ax_bar = plot_data_for_plot.plot(kind='bar', x='player_label', y=cols_to_plot, stacked=True,figsize=(12, 7),color={'Pass': '#1f77b4', 'Carry': '#ff7f0e', 'Shot xT (xG)': '#2ca02c'}) # *** ax_bar holds the axes ***
    ax_bar.set_ylabel("Total xT Added"); ax_bar.set_xlabel("Player"); ax_bar.set_title(f"xT Contribution Breakdown for Top {N_TOP_PLAYERS_PLOT} Players")
    ax_bar.legend(title='Action Type');
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    # --- SAVE PLOT 3 ---
    fig_bar = ax_bar.get_figure() # Get the figure associated with the axes
    fig3_save_path = os.path.join(PLOT_SAVE_DIR, "player_xt_breakdown.png")
    fig_bar.savefig(fig3_save_path, dpi=300, bbox_inches='tight')
    print(f"Saved Player Breakdown plot to: {fig3_save_path}")
    # --- END SAVE ---
    plt.show()
else: print("\nCould not generate player action type breakdown plot.")

# (Rest of EDA: Overall Action Type, Skipped Analyses remain the same)
xt_by_type = actions_df.groupby('type')['xt_added'].sum().sort_values(ascending=False)
print("\nOverall Total xT Added by Action Type (All Players):"); print(xt_by_type)
avg_xt_actions = actions_df[actions_df['is_successful_move'] | actions_df['is_shot']]
avg_xt_by_type = avg_xt_actions.groupby('type')['xt_added'].mean().sort_values(ascending=False)
print("\nOverall Average xT Added per Successful Action/Shot (All Players):"); print(avg_xt_by_type)

print("\n--- Skipped Analyses (Due to Data Limitations) ---")
print("NOTE: Per 90 calculations were skipped as reliable minutes played data could not be generated.")
print("NOTE: Team-level correlation and Game State analysis were skipped due to missing team IDs in source match data.")

# --- Save Results (Optional) ---
# print("\nOptional: Saving results to CSV...")

print("\n--- Analysis Complete ---")